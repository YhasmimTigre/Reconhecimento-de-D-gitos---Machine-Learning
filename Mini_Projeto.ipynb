{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 01: Reconhecimento de Dígitos\n",
    "\n",
    "### João Victor Soares Silva | Mat: 20210027300\n",
    "### Yhasmim de Souza Tigre | Mat: 20210026966 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 28 #Número de linhas e colunas das matrizes das imagens\n",
    "P_MAX = 255 #Número máximo de um pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui é só um exemplo menor de como funcionam as fórmulas da simetria no array.\n",
    "# Acho bom usar pra estudar pra apresentação, então deixei aqui.\n",
    "\n",
    "# teste = [\n",
    "# 1, 2, 3, 4,\n",
    "# 5, 6, 7, 8,\n",
    "# 9, 10, 11, 12,\n",
    "# 13, 14, 15, 16]\n",
    "\n",
    "# lin = 4\n",
    "\n",
    "# #Vertical\n",
    "# print('Vertical')\n",
    "# for i in range(lin):\n",
    "\n",
    "#     for j in range(int(lin/2)):\n",
    "#         print(f'{teste[(lin*i) + j]} + {teste[(lin*i) + (lin - j - 1)]} = {teste[(lin*i) + j] + teste[(lin*i) + (lin - j - 1)]}')\n",
    "\n",
    "# #Horizontal\n",
    "# print('\\nHorizontal')\n",
    "# for i in range(int(lin/2)):\n",
    "    \n",
    "#     for j in range(lin):\n",
    "#         print(f'{teste[(lin*i) + j]} + {teste[(lin*(lin - i - 1)) + j]} = {teste[(lin*i) + j] + teste[(lin*(lin - i - 1)) + j]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduzir (nome : str, arq : str) -> None:\n",
    "    aux = np.loadtxt (arq, delimiter = ';', dtype = str)\n",
    "    aux = np.delete (aux, 0, 0) #Removendo a linha dos nomes das colunas\n",
    "    lista_y = []\n",
    "    lista_intensidade = []\n",
    "    lista_simetria_vertical = []\n",
    "    lista_simetria_horizontal = []\n",
    "    lista_simetria = []\n",
    "\n",
    "    for i in range (len(aux)): #Salvando as labels\n",
    "        lista_y.append (int(aux[i][0]))\n",
    "    \n",
    "    aux = np.delete (aux, 0, 1) #Removendo as labels\n",
    "    \n",
    "    for i in range (len(aux)): #Calculando as intensidades\n",
    "        soma = 0\n",
    "\n",
    "        for j in range (len(aux[0])):\n",
    "            soma += int(aux[i][j])\n",
    "        \n",
    "        lista_intensidade.append(soma/P_MAX)\n",
    "    \n",
    "    for imagem in aux: #Simetria vertical\n",
    "        soma = 0\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(int(N/2)):\n",
    "                soma += abs(int(imagem[(N*i) + j]) - int(imagem[(N*i) + (N - j - 1)]))\n",
    "\n",
    "        lista_simetria_vertical.append(soma/P_MAX)\n",
    "\n",
    "    for imagem in aux: #Simetria horizontal\n",
    "        soma = 0\n",
    "\n",
    "        for i in range(int(N/2)):\n",
    "            for j in range(N):\n",
    "                soma += abs(int(imagem[(N*i) + j]) - int(imagem[N * (N - i - 1) + j]))\n",
    "\n",
    "        lista_simetria_horizontal.append(soma/P_MAX)\n",
    "    \n",
    "    for i in range (len(aux)): #Somando as simetrias\n",
    "        lista_simetria.append(lista_simetria_vertical[i] + lista_simetria_horizontal[i])\n",
    "\n",
    "    #Criando e preenchendo o novo .csv\n",
    "    dados_redux = open (f'{nome}.csv', 'w')\n",
    "\n",
    "    dados_redux.write ('label;intensidade;simetria\\n')\n",
    "    for i in range (len(aux)):\n",
    "        dados_redux.write (f'{lista_y[i]};{lista_intensidade[i]};{lista_simetria[i]}\\n')\n",
    "    \n",
    "    dados_redux.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leitor_csv (arq : str) -> np.array:\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    aux = np.loadtxt (arq, delimiter = ';', dtype = str)\n",
    "    aux = np.delete (aux, 0, 0) #Removendo a linha dos nomes das colunas\n",
    "\n",
    "    for linha in aux:\n",
    "        x.append([float(linha[1]), float(linha[2])])\n",
    "        y.append(int(linha[0]))\n",
    "    \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduzir(nome = 'train_redu', arq = 'train.csv')\n",
    "reduzir(nome = 'test_redu', arq = 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_labels (X : np.array, Y : np.array, labels : list) -> np.array:\n",
    "    if (len(labels) != 2):\n",
    "        print(\"Selecione as duas labels que deverão ser classificadas.\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    novo_X = []\n",
    "    novo_Y = []\n",
    "\n",
    "    for i in range (len(Y)):\n",
    "        if (Y[i] == labels[0]):\n",
    "            novo_X.append(X[i])\n",
    "            novo_Y.append(1)\n",
    "        \n",
    "        elif (Y[i] == labels[1]):\n",
    "            novo_X.append(X[i])\n",
    "            novo_Y.append(-1)\n",
    "    \n",
    "    return np.array(novo_X), np.array(novo_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLA ():\n",
    "    def __init__(self, n_int : int = 1000, tam_batch : int = 32) -> None:\n",
    "        self.n_int = n_int\n",
    "        self.tam_batch = tam_batch\n",
    "\n",
    "    def acuracia (self, X : np.array, Y : np.array, w_lista : np.array) -> float:\n",
    "        soma_PCC = 0\n",
    "\n",
    "        for i in range (len(X)):\n",
    "            aux = np.sign (np.sum(np.matmul(w_lista, X[i])))\n",
    "\n",
    "            if (aux == Y[i]):\n",
    "                soma_PCC += 1\n",
    "    \n",
    "        return (soma_PCC/len(X))\n",
    "    \n",
    "    def __construtor_PCI (self, X : np.array, Y : np.array) -> np.array:\n",
    "        lista_PCI_x = []\n",
    "        lista_PCI_y = []\n",
    "\n",
    "        for i in range (len(X)):\n",
    "            aux = np.sign (np.sum(np.matmul(self.w_lista, X[i])))\n",
    "\n",
    "            if (aux != Y[i]):\n",
    "                lista_PCI_x.append(X[i])\n",
    "                lista_PCI_y.append(Y[i])\n",
    "        \n",
    "        return np.array(lista_PCI_x), np.array(lista_PCI_y) \n",
    "\n",
    "    def fit (self, X : np.array, Y : np.array) -> None:\n",
    "        lista_PCI_x = X\n",
    "        lista_PCI_y = Y\n",
    "        self.w_lista = np.zeros(X.shape[1])\n",
    "        w_otimo = self.w_lista\n",
    "\n",
    "        i = 0\n",
    "        while (len(lista_PCI_x) > 0 or i < self.n_int):\n",
    "            ale_index = np.random.randint(0, len(lista_PCI_x)) #index aleatório\n",
    "            ponto_x = lista_PCI_x[ale_index]\n",
    "            ponto_y = lista_PCI_y[ale_index]\n",
    "\n",
    "            # print(ponto_x)\n",
    "            # print(ponto_y)\n",
    "            \n",
    "            aux = ponto_x * ponto_y #x * y\n",
    "            w_novo = np.add(self.w_lista, aux)\n",
    "\n",
    "            if (self.acuracia (X, Y, w_otimo) < self.acuracia (X, Y, w_novo)):\n",
    "                w_otimo = w_novo\n",
    "\n",
    "            self.w_lista = w_novo\n",
    "\n",
    "            lista_PCI_x, lista_PCI_y = self.__construtor_PCI (X = X, Y = Y)\n",
    "            i += 1\n",
    "        \n",
    "        self.w_lista = w_otimo\n",
    "\n",
    "        return\n",
    "    \n",
    "    def predict (self, X : np.array) -> np.array:\n",
    "        predict_y = [np.sign(np.matmul(i, self.w_lista)) for i in X]\n",
    "\n",
    "        return predict_y\n",
    "\n",
    "    def get_w (self) -> np.array:\n",
    "        try:\n",
    "            return self.w_lista\n",
    "        \n",
    "        except:\n",
    "            print (\"Não foi possível recuperar w. Por favor, se certifique de treinar o modelo antes.\\n\")\n",
    "\n",
    "    def set_w (self, novo_w : np.array) -> None:\n",
    "        self.w_lista = novo_w\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reg_Log ():\n",
    "    def __init__ (self, eta = 0.1, n_int = 1000, tam_batch = 32) -> None:\n",
    "        self.eta = eta\n",
    "        self.n_int = n_int\n",
    "        self.tam_batch = tam_batch\n",
    "    \n",
    "    def fit (self, X : np.array, Y : np.array, eps : float = 0.0001) -> None:\n",
    "        lista_X = X\n",
    "        lista_y = Y\n",
    "    \n",
    "        for i in range (len(X)):\n",
    "            lista_X[i].insert(0, 1) #O 1 será usado para a multiplicação com o bias posteriormente\n",
    "        \n",
    "        n_dim = len(lista_X[0])\n",
    "        n_elem = len(lista_X)\n",
    "        w_lista = np.zeros(n_dim, dtype = float)\n",
    "\n",
    "        #Cálculo dos gradientes pelo processo iterativo\n",
    "        for i in range (self.n_int):\n",
    "            vsoma = np.zeros(n_dim, dtype = float)\n",
    "\n",
    "            if (self.tam_batch) < n_elem:\n",
    "                batch_X = []\n",
    "                batch_Y = []\n",
    "                indices = rd.sample(range(n_elem), self.tam_batch)\n",
    "\n",
    "                for j in indices:\n",
    "                    batch_X.append(lista_X[j])\n",
    "                    batch_Y.append(lista_y[j])\n",
    "            \n",
    "            else:\n",
    "                batch_X = lista_X\n",
    "                batch_Y = lista_y\n",
    "            \n",
    "            for xn, yn in zip(batch_X, batch_Y):\n",
    "                vsoma += (int(yn) * float(xn)) / 1 + np.exp(np.matmul(np.transpose(yn * w_lista), xn))\n",
    "            \n",
    "            grad_t = vsoma / self.tam_batch\n",
    "\n",
    "            #Testando o minimo\n",
    "            if (np.linalg.norm(grad_t) <  eps):\n",
    "                break\n",
    "\n",
    "            w_lista = w_lista + (self.eta * grad_t)\n",
    "        \n",
    "        self.w_lista = w_lista\n",
    "\n",
    "    def predict (self, X : np.array) -> np.array:\n",
    "        aux = [1 / (1 + np.exp(- np.dot(self.w_lista, i))) for i in X]\n",
    "        predict_y = [-1 if i <= 0.5 else 1 for i in aux]\n",
    "\n",
    "        return predict_y\n",
    "\n",
    "    def get_w (self) -> np.array:\n",
    "        try:\n",
    "            return self.w_lista\n",
    "        \n",
    "        except:\n",
    "            print (\"Não foi possível recuperar w. Por favor, se certifique de treinar o modelo antes.\\n\")\n",
    "\n",
    "    def set_w (self, novo_w : np.array) -> None:\n",
    "        self.w_lista = novo_w\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação dos Dígitos 1x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório de Eficácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Dígitos Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UmVSTodos ():\n",
    "    def __init__(self, ordem : list, n_int : int = 1000, modelo = None) -> None:\n",
    "        self.modelo = modelo(n_int = n_int)\n",
    "        self.ordem = ordem\n",
    "        \n",
    "    def fit (self, X : np.array, Y : np.array) -> None:\n",
    "        novo_X = X\n",
    "        novo_Y = Y\n",
    "        fila = self.ordem\n",
    "        self.w_lista = []\n",
    "\n",
    "        while (len(fila) > 0):\n",
    "            aux = []\n",
    "            index_lista = []\n",
    "\n",
    "            #Adequando as labels\n",
    "            for i in range(len(novo_Y)):\n",
    "                if (novo_Y[i] == fila[0]):\n",
    "                    aux.append(1)\n",
    "                    index_lista.append(i)\n",
    "                \n",
    "                else:\n",
    "                    aux.append(-1)\n",
    "            \n",
    "            #Treinando os pesos de acordo com o modelo\n",
    "            novo_Y = aux\n",
    "            self.modelo.fit(X = novo_X, Y = novo_Y)\n",
    "            self.w_lista.append(self.modelo.get_w())\n",
    "\n",
    "            #Atualizando as listas, removendo as labels já treinadas\n",
    "            novo_X = np.delete (novo_X, index_lista)\n",
    "            novo_Y = np.delete (novo_Y, index_lista)\n",
    "            fila.remove(fila[0])\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict (self, X : np.array) -> np.array:\n",
    "        y_predict = [self.__predict_x(x = xi) for xi in X]\n",
    "\n",
    "        return y_predict\n",
    "\n",
    "    def __predict_x (self, x : np.array) -> int:\n",
    "        for i in range (len(self.ordem), 0, -1):\n",
    "            aux = self.modelo\n",
    "            aux.set_w(novo_w = self.w_lista[-(i - 1)])\n",
    "\n",
    "            if (aux.predict(X = x)[0] == 1):\n",
    "                return self.ordem[-i]\n",
    "            \n",
    "        else:\n",
    "            return self.__predict_x (x = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 52.41568627,  78.00784314],\n",
       "       [103.3372549 , 136.48627451],\n",
       "       [129.92156863, 145.96862745],\n",
       "       ...,\n",
       "       [100.25098039, 113.94509804],\n",
       "       [108.29019608, 111.81960784],\n",
       "       [ 92.83921569, 137.30196078]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = leitor_csv(arq = \"train_redu.csv\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m mod_labels (X \u001b[38;5;241m=\u001b[39m X_train, Y \u001b[38;5;241m=\u001b[39m y_train, labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m      2\u001b[0m PLA_teste \u001b[38;5;241m=\u001b[39m PLA()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mPLA_teste\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m w \u001b[38;5;241m=\u001b[39m PLA_teste\u001b[38;5;241m.\u001b[39mget_w()\n\u001b[1;32m      5\u001b[0m w\n",
      "Cell \u001b[0;32mIn[13], line 48\u001b[0m, in \u001b[0;36mPLA.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     45\u001b[0m aux \u001b[38;5;241m=\u001b[39m ponto_x \u001b[38;5;241m*\u001b[39m ponto_y \u001b[38;5;66;03m#x * y\u001b[39;00m\n\u001b[1;32m     46\u001b[0m w_novo \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_lista, aux)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macuracia (X, Y, w_otimo) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macuracia\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_novo\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     49\u001b[0m     w_otimo \u001b[38;5;241m=\u001b[39m w_novo\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_lista \u001b[38;5;241m=\u001b[39m w_novo\n",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m, in \u001b[0;36mPLA.acuracia\u001b[0;34m(self, X, Y, w_lista)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[1;32m     10\u001b[0m     aux \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign (np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmatmul(w_lista, X[i])))\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (aux \u001b[38;5;241m==\u001b[39m Y[i]):\n\u001b[1;32m     13\u001b[0m         soma_PCC \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (soma_PCC\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(X))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, y_train = mod_labels (X = X_train, Y = y_train, labels = [1, 5])\n",
    "PLA_teste = PLA()\n",
    "PLA_teste.fit(X = X_train, Y = y_train)\n",
    "w = PLA_teste.get_w()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "f(x) = \n",
    "\n",
    "'''\n",
    "\n",
    "line = np.linspace(-1, 1, 1000) \n",
    "plt.plot(line, m*line + b, label=\"f(x)\", c=\"green\")\n",
    "plt.show()\n",
    "\n",
    "# digitos = pd.read_csv(\"test_redu.csv\", sep = \";\")\n",
    "# sns.set_theme()\n",
    "# sns.jointplot(data=digitos, x=\"intensidade\", y=\"simetria\", hue=\"label\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UmVTodos_plot ():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório de Eficácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação dos Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementações Avançadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight-Decay para a Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a Melhor Ordem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
