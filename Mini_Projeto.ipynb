{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 01: Reconhecimento de Dígitos\n",
    "\n",
    "### João Victor Soares Silva | Mat: 20210027300\n",
    "### Yhasmim de Souza Tigre | Mat: 20210026966 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 28 #Número de linhas e colunas das matrizes das imagens\n",
    "P_MAX = 255 #Número máximo de um pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1, 2, 3])\n",
    "# b = np.array([3, 3, 3])\n",
    "\n",
    "# print(np.matmul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui é só um exemplo menor de como funcionam as fórmulas da simetria no array.\n",
    "# Acho bom usar pra estudar pra apresentação, então deixei aqui.\n",
    "\n",
    "# teste = [\n",
    "# 1, 2, 3, 4,\n",
    "# 5, 6, 7, 8,\n",
    "# 9, 10, 11, 12,\n",
    "# 13, 14, 15, 16]\n",
    "\n",
    "# lin = 4\n",
    "\n",
    "# #Vertical\n",
    "# print('Vertical')\n",
    "# for i in range(lin):\n",
    "\n",
    "#     for j in range(int(lin/2)):\n",
    "#         print(f'{teste[(lin*i) + j]} + {teste[(lin*i) + (lin - j - 1)]} = {teste[(lin*i) + j] + teste[(lin*i) + (lin - j - 1)]}')\n",
    "\n",
    "# #Horizontal\n",
    "# print('\\nHorizontal')\n",
    "# for i in range(int(lin/2)):\n",
    "    \n",
    "#     for j in range(lin):\n",
    "#         print(f'{teste[(lin*i) + j]} + {teste[(lin*(lin - i - 1)) + j]} = {teste[(lin*i) + j] + teste[(lin*(lin - i - 1)) + j]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduzir (nome : str, arq : str) -> None:\n",
    "    aux = np.loadtxt (arq, delimiter = ';', dtype = str)\n",
    "    aux = np.delete (aux, 0, 0) #Removendo a linha dos nomes das colunas\n",
    "    lista_y = []\n",
    "    lista_intensidade = []\n",
    "    lista_simetria_vertical = []\n",
    "    lista_simetria_horizontal = []\n",
    "    lista_simetria = []\n",
    "\n",
    "    for i in range (len(aux)): #Salvando as labels\n",
    "        lista_y.append (int(aux[i][0]))\n",
    "    \n",
    "    aux = np.delete (aux, 0, 1) #Removendo as labels\n",
    "    \n",
    "    for i in range (len(aux)): #Calculando as intensidades\n",
    "        soma = 0\n",
    "\n",
    "        for j in range (len(aux[0])):\n",
    "            soma += int(aux[i][j])\n",
    "        \n",
    "        lista_intensidade.append(soma/P_MAX)\n",
    "    \n",
    "    for imagem in aux: #Simetria vertical\n",
    "        soma = 0\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(int(N/2)):\n",
    "                soma += abs(int(imagem[(N*i) + j]) - int(imagem[(N*i) + (N - j - 1)]))\n",
    "\n",
    "        lista_simetria_vertical.append(soma/P_MAX)\n",
    "\n",
    "    for imagem in aux: #Simetria horizontal\n",
    "        soma = 0\n",
    "\n",
    "        for i in range(int(N/2)):\n",
    "            for j in range(N):\n",
    "                soma += abs(int(imagem[(N*i) + j]) - int(imagem[N * (N - i - 1) + j]))\n",
    "\n",
    "        lista_simetria_horizontal.append(soma/P_MAX)\n",
    "    \n",
    "    for i in range (len(aux)): #Somando as simetrias\n",
    "        lista_simetria.append(lista_simetria_vertical[i] + lista_simetria_horizontal[i])\n",
    "\n",
    "    #Criando e preenchendo o novo .csv\n",
    "    dados_redux = open (f'{nome}.csv', 'w')\n",
    "\n",
    "    dados_redux.write ('label;intensidade;simetria\\n')\n",
    "    for i in range (len(aux)):\n",
    "        dados_redux.write (f'{lista_y[i]};{lista_intensidade[i]};{lista_simetria[i]}\\n')\n",
    "    \n",
    "    dados_redux.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leitor_csv (arq : str) -> np.array:\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    aux = np.loadtxt (arq, delimiter = ';', dtype = str)\n",
    "    aux = np.delete (aux, 0, 0) #Removendo a linha dos nomes das colunas\n",
    "\n",
    "    for linha in aux:\n",
    "        x.append([float(linha[1]), float(linha[2])])\n",
    "        y.append(int(linha[0]))\n",
    "    \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduzir(nome = 'train_redu', arq = 'train.csv')\n",
    "reduzir(nome = 'test_redu', arq = 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_labels (X : np.array, Y : np.array, labels : list) -> np.array:\n",
    "    if (len(labels) != 2):\n",
    "        print(\"Selecione as duas labels que deverão ser classificadas.\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    novo_X = []\n",
    "    novo_Y = []\n",
    "\n",
    "    for i in range (len(Y)):\n",
    "        if (Y[i] == labels[0]):\n",
    "            novo_X.append(X[i])\n",
    "            novo_Y.append(1)\n",
    "        \n",
    "        elif (Y[i] == labels[1]):\n",
    "            novo_X.append(X[i])\n",
    "            novo_Y.append(-1)\n",
    "    \n",
    "    return np.array(novo_X), np.array(novo_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLA ():\n",
    "    def __init__(self, n_int : int = 1000) -> None:\n",
    "        self.n_int = n_int\n",
    "\n",
    "    def acuracia (self, X : np.array, Y : np.array, w_lista : np.array) -> float:\n",
    "        lista_x = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "        soma_PCC = 0\n",
    "\n",
    "        for i in range (len(X)):\n",
    "            aux = np.sign(np.matmul(w_lista, lista_x[i]))\n",
    "\n",
    "            if (aux == Y[i]):\n",
    "                soma_PCC += 1\n",
    "    \n",
    "        return (soma_PCC/len(X))\n",
    "    \n",
    "    def __construtor_PCI (self, X : np.array, Y : np.array) -> np.array:\n",
    "        lista_x = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "\n",
    "        lista_PCI_x = []\n",
    "        lista_PCI_y = []\n",
    "\n",
    "        for i in range (len(X)):\n",
    "            aux = np.sign(np.matmul(self.w_lista, lista_x[i]))\n",
    "\n",
    "            if (aux != Y[i]):\n",
    "                lista_PCI_x.append(lista_x[i])\n",
    "                lista_PCI_y.append(Y[i])\n",
    "        \n",
    "        return np.array(lista_PCI_x), np.array(lista_PCI_y) \n",
    "\n",
    "    def fit (self, X : np.array, Y : np.array) -> None:\n",
    "        lista_PCI_x = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "        lista_PCI_y = Y\n",
    "        self.w_lista = np.zeros(lista_PCI_x.shape[1])\n",
    "        w_otimo = self.w_lista\n",
    "\n",
    "        i = 0\n",
    "        while (len(lista_PCI_x) > 0) and (i < self.n_int):\n",
    "            ale_index = np.random.randint(0, len(lista_PCI_x)) #index aleatório\n",
    "            ponto_x = lista_PCI_x[ale_index]\n",
    "            ponto_y = lista_PCI_y[ale_index]\n",
    "            \n",
    "            aux = ponto_x * ponto_y\n",
    "            w_novo = np.add(self.w_lista, aux)\n",
    "\n",
    "            if (self.acuracia (X, Y, w_otimo) < self.acuracia (X, Y, w_novo)):\n",
    "                w_otimo = w_novo\n",
    "\n",
    "            self.w_lista = w_novo\n",
    "\n",
    "            lista_PCI_x, lista_PCI_y = self.__construtor_PCI (X = X, Y = Y)\n",
    "            i += 1\n",
    "        \n",
    "        self.w_lista = w_otimo\n",
    "\n",
    "        return\n",
    "    \n",
    "    def predict (self, X : np.array) -> np.array:\n",
    "        lista_x = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "        predict_y = [np.sign(np.matmul(i, self.w_lista)) for i in lista_x]\n",
    "\n",
    "        return predict_y\n",
    "\n",
    "    def get_w (self) -> np.array:\n",
    "        try:\n",
    "            return self.w_lista\n",
    "        \n",
    "        except:\n",
    "            print (\"Não foi possível recuperar w. Por favor, se certifique de treinar o modelo antes.\\n\")\n",
    "\n",
    "    def set_w (self, novo_w : np.array) -> None:\n",
    "        self.w_lista = novo_w\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reg_Log ():\n",
    "    def __init__ (self, eta = 0.1, n_int = 1000, tam_batch = 32) -> None:\n",
    "        self.eta = eta\n",
    "        self.n_int = n_int\n",
    "        self.tam_batch = tam_batch\n",
    "\n",
    "    def acuracia (self, X : np.array, Y : np.array) -> float:\n",
    "        y_predict = self.predict(X = X)\n",
    "        soma_PCC = 0\n",
    "\n",
    "        for i in range (len(Y)):\n",
    "            if (Y[i] == y_predict[i]):\n",
    "                soma_PCC += 1\n",
    "            \n",
    "        return (soma_PCC/len(Y))\n",
    "    \n",
    "    def fit (self, X : np.array, Y : np.array, eps : float = 0.0001) -> None:\n",
    "        lista_X = np.concatenate((np.ones((len(X), 1)), X), axis = 1) #O 1 será usado para a multiplicação com o bias posteriormente\n",
    "        lista_y = Y\n",
    "        \n",
    "        n_dim = len(lista_X[0])\n",
    "        n_elem = len(lista_X)\n",
    "        w_lista = np.zeros(n_dim, dtype = float)\n",
    "\n",
    "        #Cálculo dos gradientes pelo processo iterativo\n",
    "        for i in range (self.n_int):\n",
    "            vsoma = np.zeros(n_dim, dtype = 'float64')\n",
    "\n",
    "            if (self.tam_batch) < n_elem:\n",
    "                batch_X = []\n",
    "                batch_Y = []\n",
    "                indices = rd.sample(range(n_elem), self.tam_batch)\n",
    "\n",
    "                for j in indices:\n",
    "                    batch_X.append(lista_X[j])\n",
    "                    batch_Y.append(lista_y[j])\n",
    "            \n",
    "            else:\n",
    "                batch_X = lista_X\n",
    "                batch_Y = lista_y\n",
    "            \n",
    "            for xn, yn in zip(batch_X, batch_Y):\n",
    "                vsoma = 1 / (1 + np.exp(yn * np.dot(w_lista, xn.T).reshape(-1, 1)))\n",
    "            \n",
    "            print(batch_X)\n",
    "            print(batch_Y)\n",
    "            print(vsoma)\n",
    "            print(batch_X * batch_Y * vsoma)\n",
    "            grad_t = (-1 / self.tam_batch) * np.sum(batch_X * batch_Y * vsoma, axis = 0)\n",
    "\n",
    "            #Testando o minimo\n",
    "            if (np.linalg.norm(grad_t) <  eps):\n",
    "                break\n",
    "\n",
    "            w_lista = w_lista - (self.eta * grad_t)\n",
    "        \n",
    "        self.w_lista = w_lista\n",
    "\n",
    "    def predict (self, X : np.array) -> np.array:\n",
    "        lista_X = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "\n",
    "        aux = [1 / (1 + np.exp(- np.matmul(np.transpose(self.w_lista), i))) for i in lista_X]\n",
    "        predict_y = [1 if i >= 0.5 else -1 for i in aux]\n",
    "\n",
    "        return predict_y\n",
    "\n",
    "    def get_w (self) -> np.array:\n",
    "        try:\n",
    "            return self.w_lista\n",
    "        \n",
    "        except:\n",
    "            print (\"Não foi possível recuperar w. Por favor, se certifique de treinar o modelo antes.\\n\")\n",
    "\n",
    "    def set_w (self, novo_w : np.array) -> None:\n",
    "        self.w_lista = novo_w\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = leitor_csv (arq = \"train_redu.csv\")\n",
    "X_test, y_test = leitor_csv (arq = \"test_redu.csv\")\n",
    "\n",
    "X_train, y_train = mod_labels (X = X_train, Y = y_train, labels = [1, 5])\n",
    "X_test, y_test = mod_labels (X = X_test, Y = y_test, labels = [1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([  1.        ,  98.00784314, 130.65882353]), array([ 1.        , 45.4745098 , 73.78039216]), array([  1.        ,  91.39215686, 125.30980392]), array([  1.        , 101.86666667, 130.25098039]), array([  1.        ,  87.29411765, 127.42745098]), array([ 1.        , 60.27843137, 85.51372549]), array([  1.        ,  95.86666667, 127.21568627]), array([  1.        , 102.48627451, 125.75686275]), array([  1.        ,  97.40784314, 128.50980392]), array([ 1.        , 66.16470588, 86.7372549 ]), array([  1.        ,  98.23137255, 135.10588235]), array([  1.        ,  96.43921569, 128.32156863]), array([ 1.        , 49.34509804, 77.79607843]), array([  1.        ,  86.96470588, 134.20392157]), array([ 1.        , 60.30980392, 70.23529412]), array([ 1.        , 44.70196078, 69.27058824]), array([ 1.        , 50.27843137, 61.21568627]), array([ 1.        , 68.14117647, 73.46666667]), array([  1.        ,  90.05098039, 113.61568627]), array([ 1.        , 46.23137255, 76.89411765]), array([ 1.        , 55.60392157, 75.86666667]), array([  1.        ,  95.85098039, 131.86666667]), array([  1.        ,  86.58039216, 118.66666667]), array([  1.        ,  94.45098039, 132.74509804]), array([  1.        , 101.12941176, 122.32941176]), array([  1.        ,  96.10980392, 122.25882353]), array([ 1.        , 48.69803922, 83.3254902 ]), array([ 1.        , 60.38431373, 72.10980392]), array([  1.        ,  98.11372549, 128.98039216]), array([ 1.        , 45.25098039, 68.93333333]), array([ 1.        , 45.36862745, 76.65882353]), array([ 1.        , 50.6627451 , 84.72156863])]\n",
      "[-1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, 1, 1]\n",
      "[[0.5]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logr \u001b[38;5;241m=\u001b[39m Reg_Log()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlogr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m w \u001b[38;5;241m=\u001b[39m logr\u001b[38;5;241m.\u001b[39mget_w()\n\u001b[1;32m      4\u001b[0m w\n",
      "Cell \u001b[0;32mIn[14], line 48\u001b[0m, in \u001b[0;36mReg_Log.fit\u001b[0;34m(self, X, Y, eps)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch_Y)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(vsoma)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbatch_X\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_Y\u001b[49m \u001b[38;5;241m*\u001b[39m vsoma)\n\u001b[1;32m     49\u001b[0m grad_t \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtam_batch) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(batch_X \u001b[38;5;241m*\u001b[39m batch_Y \u001b[38;5;241m*\u001b[39m vsoma, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#Testando o minimo\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "logr = Reg_Log()\n",
    "logr.fit(X = X_train, Y = y_train)\n",
    "w = logr.get_w()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5934819897084048\n"
     ]
    }
   ],
   "source": [
    "print(logr.acuracia(X = X_test, Y = y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação dos Dígitos 1x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório de Eficácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de Dígitos Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UmVSTodos ():\n",
    "    def __init__ (self, ordem : list, n_int : int = 1000, modelo = None) -> None:\n",
    "        self.modelo = modelo(n_int = n_int)\n",
    "        self.ordem = ordem\n",
    "        \n",
    "    def fit (self, X : np.array, Y : np.array) -> None:\n",
    "        novo_X = X\n",
    "        novo_Y = Y\n",
    "        fila = self.ordem\n",
    "        self.w_lista = []\n",
    "\n",
    "        while (len(fila) > 0):\n",
    "            aux = []\n",
    "            index_lista = []\n",
    "\n",
    "            #Adequando as labels\n",
    "            for i in range(len(novo_Y)):\n",
    "                if (novo_Y[i] == fila[0]):\n",
    "                    aux.append(1)\n",
    "                    index_lista.append(i)\n",
    "                \n",
    "                else:\n",
    "                    aux.append(-1)\n",
    "            \n",
    "            #Treinando os pesos de acordo com o modelo\n",
    "            novo_Y = aux\n",
    "            self.modelo.fit(X = novo_X, Y = novo_Y)\n",
    "            self.w_lista.append(self.modelo.get_w())\n",
    "\n",
    "            #Atualizando as listas, removendo as labels já treinadas\n",
    "            novo_X = np.delete (novo_X, index_lista)\n",
    "            novo_Y = np.delete (novo_Y, index_lista)\n",
    "            fila.remove(fila[0])\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict (self, X : np.array) -> np.array:\n",
    "        y_predict = [self.__predict_x(x = xi) for xi in X]\n",
    "\n",
    "        return y_predict\n",
    "\n",
    "    def __predict_x (self, x : np.array) -> int:\n",
    "        for i in range (len(self.ordem), 0, -1):\n",
    "            aux = self.modelo\n",
    "            aux.set_w(novo_w = self.w_lista[-(i - 1)])\n",
    "\n",
    "            if (aux.predict(X = x)[0] == 1):\n",
    "                return self.ordem[-i]\n",
    "            \n",
    "        else:\n",
    "            return self.__predict_x (x = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_1vtodos = UmVSTodos(ordem = [0, 1, 4, 5], modelo = PLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny = ax + b\\n\\nf(x) = w[1] * x - w[2] * y + w[0]\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y = ax + b\n",
    "\n",
    "f(x) = w[1] * x - w[2] * y + w[0]\n",
    "'''\n",
    "\n",
    "# digitos = pd.read_csv(\"test_redu.csv\", sep = \";\")\n",
    "# sns.set_theme()\n",
    "# sns.jointplot(data=digitos, x=\"intensidade\", y=\"simetria\", hue=\"label\", palette=\"Set2\")\n",
    "\n",
    "# line = np.linspace(np.min(X_test), np.max(X_test), 1000) \n",
    "# plt.plot(line, (-w[0] - w[1]*line) / w[2], c='orange')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UmVTodos_plot ():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório de Eficácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação dos Classificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementações Avançadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight-Decay para a Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a Melhor Ordem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
